{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUvCDXiGSGdv"
      },
      "source": [
        "# Welcome to my kernel\n",
        "Skin cancer is the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions.\n",
        "\n",
        "This the **HAM10000 (\"Human Against Machine with 10000 training images\")** dataset.It consists of 10015 dermatoscopicimages which are released as a training set for academic machine learning purposes and are publiclyavailable through the ISIC archive. This benchmark dataset can be used for machine learning and for comparisons with human experts.\n",
        "\n",
        "It has 7 different classes of skin cancer which are listed below :<br>\n",
        "**1. Melanocytic nevi <br>**\n",
        "**2. Melanoma <br>**\n",
        "**3. Benign keratosis-like lesions <br>**\n",
        "**4. Basal cell carcinoma <br>**\n",
        "**5. Actinic keratoses <br>**\n",
        "**6. Vascular lesions <br>**\n",
        "**7. Dermatofibroma<br>**\n",
        "\n",
        "In this kernel I will try to detect 7 different classes of skin cancer using Convolution Neural Network with keras tensorflow in backend and then analyse the result to see how the model can be useful in practical scenario.<br>\n",
        "We will move step by step process to classify 7 classes of cancer.\n",
        "\n",
        "In this kernel I have followed following 14 steps for model building and evaluation which are as follows : <br>\n",
        "**Step 1 : Importing Essential Libraries**<br>\n",
        "**Step 2: Making Dictionary of images and labels** <br>\n",
        "**Step 3: Reading and Processing Data** <br>\n",
        "**Step 4: Data Cleaning** <br>\n",
        "**Step 5: Exploratory data analysis (EDA)** <br>\n",
        "**Step 6: Loading & Resizing of images **<br>\n",
        "**Step 7: Train Test Split**<br>\n",
        "**Step 8: Normalization**<br>\n",
        "**Step 9: Label Encoding** <br>\n",
        "**Step 10: Train validation split** <br>\n",
        "**Step 11: Model Building (CNN)** <br>\n",
        "**Step 12: Setting Optimizer & Annealing** <br>\n",
        "**Step 13: Fitting the model**<br>\n",
        "**Step 14: Model Evaluation (Testing and validation accuracy, confusion matrix, analysis of misclassified instances)** <br>\n",
        "\n",
        "<img src=\"https://image.ibb.co/n8PBkL/cover.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2erxMg5kj1H",
        "outputId": "4197704c-731a-45e3-b782-db3e4083bd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ttMygdfSGdx"
      },
      "source": [
        "# Step 1 : importing Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3nXR-l6SGdx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "np.random.seed(123)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "import itertools\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ggK3nlLIsomD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_6M-_yLSGdy"
      },
      "outputs": [],
      "source": [
        "#1. Function to plot model's validation loss and validation accuracy\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPFviWBNSGdz"
      },
      "source": [
        "# Step 2 : Making Dictionary of images and labels\n",
        "In this step I have made the image path dictionary by joining the folder path from base directory base_skin_dir and merge the images in jpg format from both the folders HAM10000_images_part1.zip and HAM10000_images_part2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TxS084RSGd0"
      },
      "outputs": [],
      "source": [
        "base_skin_dir = '/content/drive/MyDrive/COLABDATA/hm10000'\n",
        "\n",
        "# Merging images from both folders HAM10000_images_part1.zip and HAM10000_images_part2.zip into one dictionary\n",
        "\n",
        "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
        "                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n",
        "\n",
        "# This dictionary is useful for displaying more human-friendly labels later on\n",
        "\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZHz07KySGd0"
      },
      "source": [
        "# Step 3 : Reading & Processing data\n",
        "\n",
        "In this step we have read the csv by joining the path of image folder which is the base folder where all the images are placed named base_skin_dir.\n",
        "After that we made some new columns which is easily understood for later reference such as we have made column path which contains the image_id, cell_type which contains the short name of lesion type and at last we have made the categorical column cell_type_idx in which we have categorize the lesion type in to codes from 0 to 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo8zE8XySGd1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "skin_df = pd.read_csv(os.path.join('/content/drive/MyDrive/COLABDATA/hm10000', 'HAM10000_metadata.csv'))\n",
        "\n",
        "# Creating New Columns for better readability\n",
        "\n",
        "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n",
        "skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get)\n",
        "skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DL7UmK2_SGd1",
        "outputId": "76f4ea86-2b51-4f98-e610-95f664c809a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
              "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp   \n",
              "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
              "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
              "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
              "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
              "...            ...           ...    ...     ...   ...     ...          ...   \n",
              "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
              "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
              "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
              "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
              "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
              "\n",
              "                                                    path  \\\n",
              "0      /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "1      /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "2      /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "3      /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "4      /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "...                                                  ...   \n",
              "10010  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "10011  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "10012  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "10013  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "10014  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "\n",
              "                            cell_type  cell_type_idx  \n",
              "0      Benign keratosis-like lesions               2  \n",
              "1      Benign keratosis-like lesions               2  \n",
              "2      Benign keratosis-like lesions               2  \n",
              "3      Benign keratosis-like lesions               2  \n",
              "4      Benign keratosis-like lesions               2  \n",
              "...                               ...            ...  \n",
              "10010               Actinic keratoses              0  \n",
              "10011               Actinic keratoses              0  \n",
              "10012               Actinic keratoses              0  \n",
              "10013               Actinic keratoses              0  \n",
              "10014                        Melanoma              5  \n",
              "\n",
              "[10015 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f98e9cb-efa5-4751-9631-a2ee8fb30b3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>path</th>\n",
              "      <th>cell_type</th>\n",
              "      <th>cell_type_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033084</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033550</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033536</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>ISIC_0032854</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Actinic keratoses</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>ISIC_0032258</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>70.0</td>\n",
              "      <td>female</td>\n",
              "      <td>back</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Melanoma</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f98e9cb-efa5-4751-9631-a2ee8fb30b3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f98e9cb-efa5-4751-9631-a2ee8fb30b3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f98e9cb-efa5-4751-9631-a2ee8fb30b3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0019cb58-9389-433f-bfd4-3a1bd4417f90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0019cb58-9389-433f-bfd4-3a1bd4417f90')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0019cb58-9389-433f-bfd4-3a1bd4417f90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Now lets see the sample of tile_df to look on newly made columns\n",
        "skin_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM5r8ByQSGd2"
      },
      "source": [
        "# Step 4 : Data Cleaning\n",
        "In this step we check for Missing values and datatype of each field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLKTDNaWSGd2",
        "outputId": "aeebf9b5-1ad2-4920-bba7-a71889eb943c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id         0\n",
              "image_id          0\n",
              "dx                0\n",
              "dx_type           0\n",
              "age              57\n",
              "sex               0\n",
              "localization      0\n",
              "path              0\n",
              "cell_type         0\n",
              "cell_type_idx     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-hKGttASGd3"
      },
      "source": [
        "As it is evident from the above that only age has null values which is 57 so we will fill the null values by their mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-X0AA0ZSGd3"
      },
      "outputs": [],
      "source": [
        "skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Yk4TIPSGd3"
      },
      "source": [
        "Now, lets check the presence of null values  again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJgLT3SSSGd4",
        "outputId": "f9685bd3-3d7b-4739-9101-ed23ab8bd9b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lesion_id        0\n",
              "image_id         0\n",
              "dx               0\n",
              "dx_type          0\n",
              "age              0\n",
              "sex              0\n",
              "localization     0\n",
              "path             0\n",
              "cell_type        0\n",
              "cell_type_idx    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "skin_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OuMrCR2SGd4",
        "outputId": "4447cd94-d1c2-442a-f550-974372a6b055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lesion_id         object\n",
            "image_id          object\n",
            "dx                object\n",
            "dx_type           object\n",
            "age              float64\n",
            "sex               object\n",
            "localization      object\n",
            "path              object\n",
            "cell_type         object\n",
            "cell_type_idx       int8\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(skin_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XVIgavSGd8"
      },
      "source": [
        "# Step 6: Loading and resizing of images\n",
        "In this step images will be loaded into the column named image from the image path from the image folder. We also resize the images as the original dimension of images are 450 x 600 x3 which TensorFlow can't handle, so that's why we resize it into 100 x 75. As this step resize all the 10015 images dimensions into 100x 75 so be patient it will take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew3qTJGySGd9"
      },
      "outputs": [],
      "source": [
        "skin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir7AW9TxSGd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ac7c3cae-7483-4db1-cfc8-29ba1ce9fe22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
              "\n",
              "                                                path  \\\n",
              "0  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "1  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "2  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "3  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "4  /content/drive/MyDrive/COLABDATA/hm10000/HAM10...   \n",
              "\n",
              "                        cell_type  cell_type_idx  \\\n",
              "0  Benign keratosis-like lesions               2   \n",
              "1  Benign keratosis-like lesions               2   \n",
              "2  Benign keratosis-like lesions               2   \n",
              "3  Benign keratosis-like lesions               2   \n",
              "4  Benign keratosis-like lesions               2   \n",
              "\n",
              "                                               image  \n",
              "0  [[[190, 153, 194], [192, 154, 196], [191, 153,...  \n",
              "1  [[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...  \n",
              "2  [[[185, 127, 137], [189, 133, 147], [194, 136,...  \n",
              "3  [[[24, 11, 17], [26, 13, 22], [38, 21, 32], [5...  \n",
              "4  [[[134, 90, 113], [147, 102, 125], [159, 115, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb023988-060b-4aa4-9707-a4667233a4af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>path</th>\n",
              "      <th>cell_type</th>\n",
              "      <th>cell_type_idx</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>[[[190, 153, 194], [192, 154, 196], [191, 153,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>[[[23, 13, 22], [24, 14, 24], [25, 14, 28], [3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>[[[185, 127, 137], [189, 133, 147], [194, 136,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>[[[24, 11, 17], [26, 13, 22], [38, 21, 32], [5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>/content/drive/MyDrive/COLABDATA/hm10000/HAM10...</td>\n",
              "      <td>Benign keratosis-like lesions</td>\n",
              "      <td>2</td>\n",
              "      <td>[[[134, 90, 113], [147, 102, 125], [159, 115, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb023988-060b-4aa4-9707-a4667233a4af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb023988-060b-4aa4-9707-a4667233a4af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb023988-060b-4aa4-9707-a4667233a4af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dbad7bcb-0b5b-4379-9e20-16cbcbd3f6ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbad7bcb-0b5b-4379-9e20-16cbcbd3f6ae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dbad7bcb-0b5b-4379-9e20-16cbcbd3f6ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "skin_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtBJXXnVSGd9"
      },
      "source": [
        "**As we can see image column has been added in its color format code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-16xfdySGd9"
      },
      "source": [
        "Most interesting part its always better to see sample of images\n",
        "Below we will show images of each cancer type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veMhUVuTSGd9"
      },
      "outputs": [],
      "source": [
        "n_samples = 5\n",
        "fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n",
        "for n_axs, (type_name, type_rows) in zip(m_axs,\n",
        "                                         skin_df.sort_values(['cell_type']).groupby('cell_type')):\n",
        "    n_axs[0].set_title(type_name)\n",
        "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n",
        "        c_ax.imshow(c_row['image'])\n",
        "        c_ax.axis('off')\n",
        "fig.savefig('category_samples.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGelCl5oSGd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7202c5a9-62fc-4f6c-8d0a-1c1ee85f29a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75, 100, 3)    10015\n",
              "Name: image, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Checking the image size distribution\n",
        "skin_df['image'].map(lambda x: x.shape).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaKT1fBJSGd-"
      },
      "outputs": [],
      "source": [
        "features=skin_df.drop(columns=['cell_type_idx'],axis=1)\n",
        "target=skin_df['cell_type_idx']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs9cmf49SGd-"
      },
      "source": [
        "# Step 7 : Train Test Split\n",
        "In this step we have splitted the dataset into training and testing set of 80:20 ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T56WUGO-SGd-"
      },
      "outputs": [],
      "source": [
        "x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LND52T4KSGd_"
      },
      "source": [
        "# Step 8 : Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF_kuRSvSGd_"
      },
      "source": [
        "I choosed to normalize the x_train, x_test by substracting from theor mean values and then dividing by thier standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OI_nyT-SGd_"
      },
      "outputs": [],
      "source": [
        "x_train = np.asarray(x_train_o['image'].tolist())\n",
        "x_test = np.asarray(x_test_o['image'].tolist())\n",
        "\n",
        "x_train_mean = np.mean(x_train)\n",
        "x_train_std = np.std(x_train)\n",
        "\n",
        "x_test_mean = np.mean(x_test)\n",
        "x_test_std = np.std(x_test)\n",
        "\n",
        "x_train = (x_train - x_train_mean)/x_train_std\n",
        "x_test = (x_test - x_test_mean)/x_test_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNuft-XSGeA"
      },
      "source": [
        "# Step 9 : Label Encoding\n",
        "Labels are 7 different classes of skin cancer types from 0 to 6. We need to encode these lables to one hot vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMuq8PnHSGeA"
      },
      "outputs": [],
      "source": [
        "# Perform one-hot encoding on the labels\n",
        "y_train = to_categorical(y_train_o, num_classes = 7)\n",
        "y_test = to_categorical(y_test_o, num_classes = 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftdFyHC5SGeA"
      },
      "source": [
        "# Step 10 : Splitting training and validation split\n",
        "I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEwHYGDtSGeB"
      },
      "outputs": [],
      "source": [
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drHDQT-2SGeB"
      },
      "outputs": [],
      "source": [
        "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
        "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
        "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1Lb-53SGeB"
      },
      "source": [
        "# Step 11: Model Building\n",
        "# CNN\n",
        "I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n",
        "\n",
        "The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n",
        "\n",
        "The CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n",
        "\n",
        "The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n",
        "\n",
        "Combining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n",
        "\n",
        "Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n",
        "\n",
        "'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.\n",
        "\n",
        "The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.\n",
        "\n",
        "In the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl4VwRIuSGeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30cbdbc-25c9-4a0b-f191-f35ff3375e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 75, 100, 32)       896       \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 75, 100, 32)       9248      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 37, 50, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 37, 50, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 37, 50, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 18, 25, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 18, 25, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 18, 25, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 18, 25, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 9, 12, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 9, 12, 256)        295168    \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 9, 12, 256)        590080    \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 9, 12, 256)        590080    \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 4, 6, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 4, 6, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 4, 6, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 2, 3, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               786944    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,733,351\n",
            "Trainable params: 4,733,351\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def build_optimized_vgg16(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    # Block 1\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    # Classification block\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))  # Add Dropout layer with a dropout rate of 0.5\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))  # Add Dropout layer with a dropout rate of 0.5\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the input shape and number of classes\n",
        "input_shape = (75, 100, 3)\n",
        "num_classes = 7\n",
        "\n",
        "# Build the optimized VGG16 model\n",
        "model = build_optimized_vgg16(input_shape, num_classes)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuuV6KZJSGeC"
      },
      "source": [
        "# Step 12: Setting Optimizer and Annealer\n",
        "\n",
        "Once our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n",
        "We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n",
        "The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n",
        "I choosed Adam optimizer because it combines the advantages of two other extensions of stochastic gradient descent. Specifically:\n",
        "\n",
        "1. Adaptive Gradient Algorithm (AdaGrad) that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n",
        "\n",
        "2. Root Mean Square Propagation (RMSProp) that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\n",
        "\n",
        "Adam realizes the benefits of both AdaGrad and RMSProp.\n",
        "\n",
        "Adam is a popular algorithm in the field of deep learning because it achieves good results fast.\n",
        "\n",
        "The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdNxsnIZSGeC"
      },
      "source": [
        "# Data Augmentation\n",
        "It is the optional step. In order to avoid overfitting problem, we need to expand artificially our HAM 10000 dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations\n",
        "\n",
        "Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n",
        "\n",
        "By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to7TFd6JSGeD"
      },
      "outputs": [],
      "source": [
        "# With data augmentation to prevent overfitting\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfjD9Gj4SGeD"
      },
      "source": [
        "For the data augmentation, i choosed to :\n",
        "Randomly rotate some training images by 10 degrees Randomly Zoom by 10% some training images Randomly shift images horizontally by 10% of the width Randomly shift images vertically by 10% of the height\n",
        "Once our model is ready, we fit the training dataset ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwKBqdmpSGeD"
      },
      "outputs": [],
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                            patience=3,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btfPUzB5SGeD"
      },
      "source": [
        "# Step 13: Fitting the model\n",
        "In this step finally I fit the model into x_train, y_train. In this step I have choosen batch size of 10 and 50 epochs   as small as your batch size will be more efficiently your model will train and I have choosen 50 epochs to give the model sufficient epochs to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOz1ARYGSGeD"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AxZFLEiSGeD",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bdbdd9-93be-41c8-ada1-ac3ff09c36c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-63703d5b2f52>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "720/721 [============================>.] - ETA: 0s - loss: 1.1835 - accuracy: 0.6572"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 29s 30ms/step - loss: 1.1829 - accuracy: 0.6574 - val_loss: 1.1255 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1387 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 30ms/step - loss: 1.1387 - accuracy: 0.6712 - val_loss: 1.1273 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1379 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1379 - accuracy: 0.6712 - val_loss: 1.1173 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1340 - accuracy: 0.6709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1336 - accuracy: 0.6712 - val_loss: 1.1199 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1326 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 30ms/step - loss: 1.1326 - accuracy: 0.6712 - val_loss: 1.1169 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1314 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 30ms/step - loss: 1.1313 - accuracy: 0.6712 - val_loss: 1.1161 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1319 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1319 - accuracy: 0.6712 - val_loss: 1.1174 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1319 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1319 - accuracy: 0.6712 - val_loss: 1.1171 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1320 - accuracy: 0.6708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1311 - accuracy: 0.6712 - val_loss: 1.1198 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1307 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1307 - accuracy: 0.6712 - val_loss: 1.1210 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1322 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1319 - accuracy: 0.6712 - val_loss: 1.1169 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1304 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1307 - accuracy: 0.6712 - val_loss: 1.1150 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1300 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1297 - accuracy: 0.6712 - val_loss: 1.1172 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1306 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1308 - accuracy: 0.6712 - val_loss: 1.1176 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1304 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1299 - accuracy: 0.6712 - val_loss: 1.1168 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1302 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1302 - accuracy: 0.6712 - val_loss: 1.1151 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1306 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1305 - accuracy: 0.6712 - val_loss: 1.1200 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1299 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1302 - accuracy: 0.6712 - val_loss: 1.1217 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1314 - accuracy: 0.6708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 24s 33ms/step - loss: 1.1303 - accuracy: 0.6712 - val_loss: 1.1183 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1299 - accuracy: 0.6714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1306 - accuracy: 0.6712 - val_loss: 1.1158 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1301 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1301 - accuracy: 0.6712 - val_loss: 1.1195 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1298 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1298 - accuracy: 0.6712 - val_loss: 1.1158 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1302 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1302 - accuracy: 0.6712 - val_loss: 1.1164 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1315 - accuracy: 0.6709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1307 - accuracy: 0.6712 - val_loss: 1.1154 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1303 - accuracy: 0.6710"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1299 - accuracy: 0.6712 - val_loss: 1.1174 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1296 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1296 - accuracy: 0.6712 - val_loss: 1.1155 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1305 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1305 - accuracy: 0.6712 - val_loss: 1.1172 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1312 - accuracy: 0.6708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1305 - accuracy: 0.6712 - val_loss: 1.1192 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1299 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 24s 33ms/step - loss: 1.1299 - accuracy: 0.6712 - val_loss: 1.1176 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1298 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1298 - accuracy: 0.6712 - val_loss: 1.1159 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.6713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1295 - accuracy: 0.6712 - val_loss: 1.1165 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1288 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1288 - accuracy: 0.6712 - val_loss: 1.1154 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1302 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1302 - accuracy: 0.6712 - val_loss: 1.1200 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1298 - accuracy: 0.6714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1304 - accuracy: 0.6712 - val_loss: 1.1166 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1307 - accuracy: 0.6707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1297 - accuracy: 0.6712 - val_loss: 1.1152 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1301 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1305 - accuracy: 0.6712 - val_loss: 1.1142 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1285 - accuracy: 0.6714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1293 - accuracy: 0.6712 - val_loss: 1.1167 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1307 - accuracy: 0.6708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1299 - accuracy: 0.6712 - val_loss: 1.1141 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1303 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 23s 32ms/step - loss: 1.1303 - accuracy: 0.6712 - val_loss: 1.1173 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 30ms/step - loss: 1.1295 - accuracy: 0.6712 - val_loss: 1.1164 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1296 - accuracy: 0.6714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 24s 33ms/step - loss: 1.1299 - accuracy: 0.6712 - val_loss: 1.1155 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1298 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1298 - accuracy: 0.6712 - val_loss: 1.1166 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1303 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 20s 28ms/step - loss: 1.1303 - accuracy: 0.6712 - val_loss: 1.1178 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1290 - accuracy: 0.6712 - val_loss: 1.1156 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "719/721 [============================>.] - ETA: 0s - loss: 1.1297 - accuracy: 0.6709"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 30ms/step - loss: 1.1294 - accuracy: 0.6712 - val_loss: 1.1190 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.6711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 29ms/step - loss: 1.1296 - accuracy: 0.6712 - val_loss: 1.1149 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1291 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 30ms/step - loss: 1.1291 - accuracy: 0.6712 - val_loss: 1.1214 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "720/721 [============================>.] - ETA: 0s - loss: 1.1297 - accuracy: 0.6714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 21s 28ms/step - loss: 1.1301 - accuracy: 0.6712 - val_loss: 1.1161 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1291 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1291 - accuracy: 0.6712 - val_loss: 1.1199 - val_accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "721/721 [==============================] - ETA: 0s - loss: 1.1297 - accuracy: 0.6712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r721/721 [==============================] - 22s 31ms/step - loss: 1.1297 - accuracy: 0.6712 - val_loss: 1.1178 - val_accuracy: 0.6808 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "epochs = 50\n",
        "batch_size = 10\n",
        "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (x_validate,y_validate),\n",
        "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
        "                              , callbacks=[learning_rate_reduction])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKDrljsSGeE"
      },
      "source": [
        "# Step 14: Model Evaluation\n",
        "In this step we will check the testing accuracy and validation accuracy of our model,plot confusion matrix and also check the missclassified images count of each type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpg2zgXwSGeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b180b3-76d8-47dc-8552-53aca4b37272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 15ms/step - loss: 0.9611 - accuracy: 0.6820\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9422 - accuracy: 0.6870\n",
            "Validation: accuracy = 0.687032  ;  loss_v = 0.942204\n",
            "Test: accuracy = 0.681977  ;  loss = 0.961099\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n",
        "model.save(\"model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2SFQ97CSGeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "outputId": "3c619da0-b170-4c12-8cfd-6564b733bd27"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1453b2ee3828>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-27d892348553>\u001b[0m in \u001b[0;36mplot_model_history\u001b[0;34m(model_history)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_model_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5dyho_oSGeE"
      },
      "outputs": [],
      "source": [
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(x_validate)\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_validate,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
        "\n",
        "\n",
        "\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNqA6_VESGeF"
      },
      "source": [
        "Now, lets which category has much incorrect predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_rflOXSSGeF"
      },
      "outputs": [],
      "source": [
        "label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n",
        "plt.bar(np.arange(7),label_frac_error)\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Fraction classified incorrectly')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzAhqk4zSGeF"
      },
      "source": [
        "# Conclusion\n",
        "It seems our model has maximum number of incorrect predictions for Basal cell carcinoma which has code 3, then second most missclassified type is Vascular lesions code 5 then Melanocytic nevi code  0 where as Actinic keratoses code 4 has least misclassified type.\n",
        "\n",
        "We can also further tune our model to easily achieve the accuracy above 80% and I think still this model is efficient in comparison to detection with human eyes having 77.0344% accuracy\n",
        "\n",
        "I hope kagglers like my stepwise approach to classify cancer types. If like then kindly dont forget to hit the **like**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvQd8jTBSGeF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}